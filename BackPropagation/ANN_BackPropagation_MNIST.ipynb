{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Backprop_MNIST_Luis_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrgR4QVdZr0a",
        "colab_type": "text"
      },
      "source": [
        "# Obtenção dos Dados\n",
        "\n",
        "Este código baixa os arquivos do [_dataset_ MNIST](https://en.wikipedia.org/wiki/MNIST_database) a partir do [site](http://yann.lecun.com/exdb/mnist/) do [Prof. Yann LeCun](https://en.wikipedia.org/wiki/Yann_LeCun)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0vUxLwaZIRa",
        "colab_type": "text"
      },
      "source": [
        "#-------------------------------------------------------------------------------\n",
        "#--         Federal University of Santa Maria             \n",
        "#--               Technology Center            \n",
        "#--            Computer Engineering Course\n",
        "#--\n",
        "#-- Author      : Luis Felipe de Deus                           \n",
        "#--\n",
        "#-- Created     : 21 May 2020\n",
        "#-- Update      : 22 May 2020                                                  \n",
        "#-------------------------------------------------------------------------------\n",
        "####### JUST A SMALL IMPLEMENTATION OF ARTIFICIAL NEURAL NETWORK\n",
        "####### USING FEEDFORWARD APPROACH\n",
        "####### WITH BACKPROPAGATION APPROACH WITHOUT LIBRARIES\n",
        "####### THE NUMBER OF NEURONS FOR EACH LAYER IS PARAMETRIZABLE\n",
        "####### THE NUMBER OF HIDDEN LAYERS IS ALSO PARAMETRIZABLE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRzAR1ruTVz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import the Libraries we need\n",
        "import numpy as np\n",
        "from struct import unpack\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1ysJPoDYhDm",
        "colab_type": "code",
        "outputId": "37b998a6-b39b-4ce4-e57b-5015775db0da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        }
      },
      "source": [
        "# Training images \n",
        "!wget http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz -O train-images-idx3-ubyte.gz\n",
        "# Labels for training \n",
        "!wget http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz -O train-labels-idx1-ubyte.gz\n",
        "# Validation images\n",
        "!wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz -O t10k-images-idx3-ubyte.gz\n",
        "# Labels for validation\n",
        "!wget http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz -O t10k-labels-idx1-ubyte.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-26 13:04:00--  http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Resolving yann.lecun.com (yann.lecun.com)... 104.28.7.204, 104.28.6.204, 2606:4700:3031::681c:6cc, ...\n",
            "Connecting to yann.lecun.com (yann.lecun.com)|104.28.7.204|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9912422 (9.5M) [application/x-gzip]\n",
            "Saving to: ‘train-images-idx3-ubyte.gz’\n",
            "\n",
            "\r          train-ima   0%[                    ]       0  --.-KB/s               \rtrain-images-idx3-u 100%[===================>]   9.45M  60.8MB/s    in 0.2s    \n",
            "\n",
            "2020-05-26 13:04:00 (60.8 MB/s) - ‘train-images-idx3-ubyte.gz’ saved [9912422/9912422]\n",
            "\n",
            "--2020-05-26 13:04:03--  http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Resolving yann.lecun.com (yann.lecun.com)... 104.28.7.204, 104.28.6.204, 2606:4700:3033::681c:7cc, ...\n",
            "Connecting to yann.lecun.com (yann.lecun.com)|104.28.7.204|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28881 (28K) [application/x-gzip]\n",
            "Saving to: ‘train-labels-idx1-ubyte.gz’\n",
            "\n",
            "train-labels-idx1-u 100%[===================>]  28.20K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2020-05-26 13:04:03 (2.29 MB/s) - ‘train-labels-idx1-ubyte.gz’ saved [28881/28881]\n",
            "\n",
            "--2020-05-26 13:04:07--  http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Resolving yann.lecun.com (yann.lecun.com)... 104.28.7.204, 104.28.6.204, 2606:4700:3033::681c:7cc, ...\n",
            "Connecting to yann.lecun.com (yann.lecun.com)|104.28.7.204|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1648877 (1.6M) [application/x-gzip]\n",
            "Saving to: ‘t10k-images-idx3-ubyte.gz’\n",
            "\n",
            "t10k-images-idx3-ub 100%[===================>]   1.57M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-05-26 13:04:07 (14.2 MB/s) - ‘t10k-images-idx3-ubyte.gz’ saved [1648877/1648877]\n",
            "\n",
            "--2020-05-26 13:04:08--  http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Resolving yann.lecun.com (yann.lecun.com)... 104.28.7.204, 104.28.6.204, 2606:4700:3031::681c:6cc, ...\n",
            "Connecting to yann.lecun.com (yann.lecun.com)|104.28.7.204|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4542 (4.4K) [application/x-gzip]\n",
            "Saving to: ‘t10k-labels-idx1-ubyte.gz’\n",
            "\n",
            "t10k-labels-idx1-ub 100%[===================>]   4.44K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-05-26 13:04:08 (437 MB/s) - ‘t10k-labels-idx1-ubyte.gz’ saved [4542/4542]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y07CnRjaJYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unpack files\n",
        "!gunzip *.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-GlQ5rjbPwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@brief: This function will read the file and create an 3d array\n",
        "#@param: img_filename is the filename from the desired file\n",
        "#@param: 3d array with the images\n",
        "def read_imgs(img_filename):\n",
        "  \n",
        "  # Open the file\n",
        "  img_file = open(img_filename,'rb')\n",
        "\n",
        "  # Read the file head\n",
        "  magic = unpack('>i', img_file.read(4))[0]\n",
        "  total = unpack('>i', img_file.read(4))[0]\n",
        "  height = unpack('>i', img_file.read(4))[0]\n",
        "  width = unpack('>i', img_file.read(4))[0]\n",
        "\n",
        "  #Validation test against corrupted files\n",
        "  if magic != 2051:\n",
        "    print('Erro, este arquivo não parece ser um arquivo de imagens MNIST')\n",
        "\n",
        "  #3d array with the sample (image) where the image is 28*28 pixels\n",
        "  imgs = np.zeros((total,height,width))\n",
        "\n",
        "  #Populates the array\n",
        "  for k in range(total): # Each sample k\n",
        "    for i in range(height): # Each line i\n",
        "      for j in range(width): # Each column j\n",
        "        imgs[k,i,j] = ord(img_file.read(1)) # 1 byte\n",
        "  \n",
        "  # Return the 3darray\n",
        "  return imgs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpK1CJ0mgAzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@brief: This function will read the labels and create an 2d array\n",
        "#@param: labels_filename is the filename from the desired file\n",
        "#@param: 2d array with the images\n",
        "def read_labels(labels_filename):\n",
        "  \n",
        "  # Open the file\n",
        "  labels_file = open(labels_filename,'rb')\n",
        "\n",
        "  # Read the file head\n",
        "  magic = unpack('>i', labels_file.read(4))[0]\n",
        "  total = unpack('>i', labels_file.read(4))[0]\n",
        "\n",
        "  #Validation test against corrupted files\n",
        "  if magic != 2049:\n",
        "    print('Erro, este arquivo não parece ser um arquivo de imagens MNIST')\n",
        "\n",
        "  #2d array with the sample (label)\n",
        "  labels = np.zeros((total))\n",
        "\n",
        "  #Populates the array\n",
        "  for k in range(total): # Each sample k\n",
        "    labels[k] = ord(labels_file.read(1)) #  1 byte\n",
        "  \n",
        "  # Return the 3darray\n",
        "  return labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEEgfzZli9yF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read training data\n",
        "imgs = read_imgs('train-images-idx3-ubyte')\n",
        "labels = read_labels('train-labels-idx1-ubyte')\n",
        "\n",
        "# Read validation data\n",
        "imgs_val = read_imgs('t10k-images-idx3-ubyte')\n",
        "labels_val = read_labels('t10k-labels-idx1-ubyte')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtrLJElktqPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy.random import shuffle\n",
        "\n",
        "#Shuffle the image and label arrays\n",
        "idxs = list(range(imgs.shape[0]))\n",
        "\n",
        "# Embaralhamos a lista\n",
        "shuffle(idxs)\n",
        "\n",
        "# Reorganizamos as imagens e os labels\n",
        "imgs = imgs[idxs]\n",
        "labels = labels[idxs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QVd297oHk4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@brif: This function implements the min_max normalization for a list\n",
        "#@param: data is a list with samples\n",
        "#@return: the normalized data\n",
        "def max_min_normalization(data):\n",
        "    #Normaliza the Data\n",
        "    normalized, mi, ma = [], min(data), max(data)\n",
        "    for x in data:\n",
        "        y = (x - mi) / ( ma - mi)\n",
        "        normalized.append(y)\n",
        "    return normalized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLKVKs3oHqvG",
        "colab_type": "code",
        "outputId": "2499dbb7-77bc-41d5-f73f-e54f74542f37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Create an array with 60,000 lines and 784 (28*28) columns\n",
        "# Serialize the imagem for the ANN\n",
        "X = np.zeros([imgs.shape[0], (imgs.shape[1]*imgs.shape[2])])\n",
        "\n",
        "#Populates the array X \n",
        "for e,d in enumerate(imgs):\n",
        "  dN = np.reshape(d,[d.shape[0]*d.shape[1],])\n",
        "  #X[e] = max_min_normalization(dN)\n",
        "  X[e] = (dN)/255.0\n",
        "print(\"X Shape:\",X.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X Shape: (60000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHZd5kNUK5jH",
        "colab_type": "code",
        "outputId": "a716f66d-8d7a-435a-b7d0-1daaaa3ce33d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Create an array with the desired labels, 60,000 lines and 10 columns\n",
        "# The array uses one hot encoding\n",
        "POS = 10 # Number of possibilities\n",
        "Y_des = np.zeros([labels.shape[0], POS])\n",
        "\n",
        "#Create a category array\n",
        "category = np.array([0,1,2,3,4,5,6,7,8,9]).astype('float')\n",
        "# On this loop we will codify the array with 1.00 where is the label\n",
        "# and the other 9 position with 0.00\n",
        "for i in range(labels.shape[0]):\n",
        "  Y_des[i:] = (category == labels[i]).astype('float')\n",
        "  #print((category == labels[i]).astype('float'))\n",
        "print(Y_des.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHgWKtEsSPB9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@brief: This function wll evaluate the ANN\n",
        "#@param: p is the perceptron ANN\n",
        "#@param: xTest is the validation images\n",
        "#@param: yTest is the validation labels\n",
        "def getAccuracy(p, xTest,yTest):\n",
        "  #Evaluate the accuracy\n",
        "  #Get the output for this set\n",
        "  score = 0\n",
        "  for e,xv in enumerate(xTest):\n",
        "    ypredicted = p.forward(xv)\n",
        "\n",
        "    #Find the highest value in the predict\n",
        "    n_max = max(ypredicted)\n",
        "\n",
        "    #Find the predicted label\n",
        "    for posY_pred, it in enumerate(ypredicted):\n",
        "      if(it==n_max):\n",
        "        numberPredict = posY_pred\n",
        "\n",
        "    #Find the number of label\n",
        "    for posY_des,it in enumerate(yTest[e]):\n",
        "      if(it==1.00):\n",
        "        numberTest = posY_des\n",
        "        \n",
        "    #If is the same number compute one more point\n",
        "    if(numberPredict == numberTest):\n",
        "      score+=1\n",
        "    #print(\"Pred:\",numberPredict,\" - Test:\", numberPredict)\n",
        "  acc = (score/yTest.shape[0])*100\n",
        "  #acc = score/10\n",
        "  print(\"Accuray: \", round(acc,2), \"%\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DYyh1dlPbdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@brief: Activation function\n",
        "#@param: s - is tensor to be applyed to sigmoid\n",
        "#@param: deriv - If True returns the derivative from sigmoid\n",
        "def sigmoid(s, deriv=False):\n",
        "    if (deriv == True):\n",
        "        return s * (1 - s)\n",
        "    return 1/(1 + np.exp(-s))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc0DeR840biv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Softmax function\n",
        "np.set_printoptions(formatter={'float':lambda x: '%+01.2f ' % x})\n",
        "def softmax(x):\n",
        "  ex = np.exp(x)\n",
        "  s = np.sum(ex)\n",
        "  x_sft = ex/s\n",
        " \n",
        "  return x_sft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjYjj9-rPV8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@brief: Implements a Perceptron Neural Network\n",
        "#@param: input_size - number of neurons on input layer (e.g. 4)\n",
        "#@param: hidden_layer - a list with the number of neurons on each hidden layer (e.g [4,7])\n",
        "#@param: output_layer - number of neurons on output layer\n",
        "class Perceptron:\n",
        "  def __init__(self, input_size, hidden_layer, output_layer):\n",
        "    self.ilayer = input_size\n",
        "    self.hlayer = hidden_layer\n",
        "    self.olayer = output_layer\n",
        "    #Initalize the weights and bias for hidden layers\n",
        "    pLayer = self.ilayer\n",
        "    self.Wh = []\n",
        "    self.bh = []\n",
        "    for e,it in enumerate(self.hlayer):\n",
        "      self.Wh.append(np.random.random((it,pLayer))*2.0 - 1.0)\n",
        "      self.bh.append(np.random.random((it,1))*2.0 - 1.0)\n",
        "      pLayer = it\n",
        "\n",
        "    #Initalize the weights and bias for output layer\n",
        "    self.Wo = np.random.random((self.olayer,self.hlayer[-1]))*2.0 - 1.0\n",
        "    self.bo = np.random.random((self.olayer,1))*2.0 - 1.0\n",
        "\n",
        "    #Learning step\n",
        "    self.eta = 0.1\n",
        "    \n",
        "  def forward(self,x):\n",
        "    #Reshape the entrance\n",
        "    x = np.reshape(x,(self.ilayer,1))\n",
        "\n",
        "    #Calculate S for the hidden layers\n",
        "    self.sh = []\n",
        "    self.zh = []\n",
        "    pLayer = x\n",
        "    for e,whl in enumerate(self.Wh):\n",
        "      tmpSh = np.dot(whl,pLayer) + self.bh[e]\n",
        "      self.sh.append(tmpSh)\n",
        "      #Pass S through the activation function (Sigmoid)\n",
        "      tmpZh = sigmoid(tmpSh)\n",
        "      self.zh.append(tmpZh)\n",
        "      #Update the previous layer \n",
        "      pLayer = tmpZh\n",
        "  \n",
        "    #Calculte S for output layer\n",
        "    self.so = np.dot(self.Wo,self.zh[-1]) + self.bo\n",
        "\n",
        "    #Pass S through the activation function (Sigmoid)\n",
        "    self.zo = sigmoid(self.so)\n",
        "    self.zoSoft = softmax(self.zo)\n",
        "    #Return the ANN output\n",
        "    return self.zoSoft\n",
        "\n",
        "  def train(self, Xt, Yt):\n",
        "    Err = 0\n",
        "    #For all entries, X at a time \n",
        "    for n in range(len(Xt)):\n",
        "      #Reshape the entries\n",
        "      X = np.asarray(Xt[n])\n",
        "      Y = Yt[n]\n",
        "      X = np.reshape(X,(self.ilayer,1))\n",
        "      Y = np.reshape(Y,(self.olayer,1))\n",
        "\n",
        "      #First run ANN forward and get the array\n",
        "      # with the results for the output neurons\n",
        "      self.forward(X)\n",
        "      self.yPred = self.zo\n",
        "      #print(\"Y\",self.yPred)\n",
        "      \n",
        "      #Evaluate the RMSE\n",
        "      Err = sqrt(mean_squared_error(Y, self.yPred))\n",
        "\n",
        "      #Second run the backpropagation\n",
        "      self.backpropagation(X, Y)\n",
        "\n",
        "    #Return the RMSE\n",
        "    return Err\n",
        "\n",
        "  def backpropagation(self, X, Y):\n",
        "    #For the output layer\n",
        "    #Delta Output layer (delta = (Erro) * derivative of sigmoid)\n",
        "    dOut = (self.yPred-Y) * (sigmoid(self.zo, True))\n",
        "    #Derivative of Error by Wo\n",
        "    dEwo =  np.dot(dOut, self.zh[-1].T)\n",
        "\n",
        "    ###--- Update parameters --######\n",
        "    #Bias\n",
        "    self.bo = self.bo - (self.eta*dOut)\n",
        "    #Weights\n",
        "    self.Wo = self.Wo - (self.eta*dEwo)\n",
        "\n",
        "    #For hidden layer\n",
        "    #Delta Hidden Layer (delta = (W from previuos layer) * (Previuous delta) * (derivative of sigmoid)\n",
        "    pLayerW = self.Wo\n",
        "    pLayerD = dOut\n",
        "    pZ = len(self.zh)-1\n",
        "    dHid = [] #Delta \n",
        "    dEwh = [] #Derivative of error by weight\n",
        "    for e,it in enumerate(reversed(self.zh), start=1):\n",
        "      tmpDelta = (np.dot(pLayerW.T, pLayerD)) * (sigmoid(it, True))\n",
        "      dHid.append(tmpDelta)\n",
        "      #Derivative of Error by Weight\n",
        "      if(pZ>0):\n",
        "        tmpDErro = np.dot(tmpDelta, (self.zh[pZ-1]).T)\n",
        "      else:\n",
        "        tmpDErro = np.dot(tmpDelta, (X.T))\n",
        "      #Decrease position of layer\n",
        "      pZ-=1\n",
        "\n",
        "      dEwh.append(tmpDErro)\n",
        "      #Update\n",
        "      pLayerW = self.Wh[-e] #Minus sign because it is from the end to the beginning\n",
        "      pLayerD = tmpDelta  #Keep the delta from this iteration\n",
        "\n",
        "      ###--- Update parameters --######\n",
        "      #Bias\n",
        "      self.bh[-e] = self.bh[-e] - (self.eta*tmpDelta)\n",
        "      #Weights\n",
        "      self.Wh[-e] = self.Wh[-e] - (self.eta*tmpDErro)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7cNxRpCh0Wx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "T = 0.4 #Percentage of test on the dataset. e.g. 0.4 =40% test, 60% trainning\n",
        "xTrain, xTest, yTrain, yTest = train_test_split(X, Y_des, test_size=T)\n",
        "#xTrain = X[0:24000]\n",
        "#yTrain = Y_des[0:24000]\n",
        "#xTest= X[24000:]\n",
        "#yTest = Y_des[24000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i806n2vvPvRy",
        "colab_type": "code",
        "outputId": "cc757444-7bc2-47c4-8124-759799319b46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "# Create a Neural Network\n",
        "iNeurons = X.shape[1] #Input Neurons is 28*28 pixels\n",
        "hNeurons = [256,64] #Hidden layers \n",
        "oNeurons = 10 #Output layer, one neuron for each label\n",
        "p = Perceptron(iNeurons, hNeurons, oNeurons)\n",
        "#p = PerceptronvOld(iNeurons, 256,64, oNeurons)\n",
        "\n",
        "Errl = []\n",
        "# Training for 10 times\n",
        "for i in range(10):\n",
        "\n",
        "  # One step\n",
        "  Err = p.train(xTrain, yTrain)\n",
        "  #Err = p.backprop(xTrain, yTrain)\n",
        "\n",
        "  print('RMSE = ',Err)\n",
        "  Errl.append(Err)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE =  0.16278059686929275\n",
            "RMSE =  0.09878537211250411\n",
            "RMSE =  0.05452462817928213\n",
            "RMSE =  0.024410867108632564\n",
            "RMSE =  0.016628392170902912\n",
            "RMSE =  0.011376443820190062\n",
            "RMSE =  0.007879999272019485\n",
            "RMSE =  0.005877946314740545\n",
            "RMSE =  0.005063212108295293\n",
            "RMSE =  0.0038436453620926733\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1_JajoRoXZ_",
        "colab_type": "code",
        "outputId": "59bcbffb-aaf4-47cd-d945-08d38632d441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Here we call the function to evaluate the ANN\n",
        "#We use different dataset (Test set) and get\n",
        "#the accuracy from the ANN\n",
        "getAccuracy(p, xTest, yTest)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuray:  95.6 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgxKGQUpF0kz",
        "colab_type": "code",
        "outputId": "7828ee2f-c065-475e-d118-b57f6ab8363f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "#Just show one image\n",
        "n = np.random.randint(60000, size=2)\n",
        "print(n)\n",
        "for i in n:\n",
        "  print(labels[i])\n",
        "  plt.imshow(imgs[i])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[13189 37780]\n",
            "8.0\n",
            "6.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}